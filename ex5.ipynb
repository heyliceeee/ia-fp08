{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T09:05:10.432555Z",
     "start_time": "2025-04-16T09:05:10.429149Z"
    }
   },
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Utilize agr a abordagem de meta-learning do H2O: AutoML. Esta abordagem automatiza o processo de pesquisa de um modelo de ML, testando em sequência diferentes algoritmos e configs, c intervenção humana mín. Corra o AutoML durante o tempo pretendido (e.g. 1h) e compare o mlhr modelo obtido por este processo c o mlhr modelo obtido de entre os exercícios anteriores:",
   "id": "cfca7aa9f2f4a8d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:03:39.086823Z",
     "start_time": "2025-04-16T09:03:24.423494Z"
    }
   },
   "cell_type": "code",
   "source": "h2o.init()",
   "id": "a9a1ad9a3b16b880",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "--------------------------  ---------------------------------\n",
       "H2O_cluster_uptime:         50 mins 19 secs\n",
       "H2O_cluster_timezone:       Europe/Lisbon\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    19 days\n",
       "H2O_cluster_name:           H2O_from_python_Alice_Dias_d0aocp\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.461 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.9 final\n",
       "--------------------------  ---------------------------------"
      ],
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>50 mins 19 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Lisbon</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>19 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Alice_Dias_d0aocp</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.461 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:05:34.763516Z",
     "start_time": "2025-04-16T09:05:14.134253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carregamento dos dados\n",
    "train = h2o.import_file(\"train.csv\")\n",
    "test = h2o.import_file(\"test.csv\")\n",
    "\n",
    "# Remover colunas irrelevantes\n",
    "train = train.drop([\"C1\", \"id\"])\n",
    "test = test.drop([\"C1\", \"id\"])\n",
    "\n",
    "# Definir target e features\n",
    "target = \"satisfaction\"\n",
    "features = [col for col in train.columns if col != target]\n",
    "\n",
    "# Converter target para categórico, se ainda não for\n",
    "train[target] = train[target].asfactor()"
   ],
   "id": "4888321da1e390c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T09:19:35.705232Z",
     "start_time": "2025-04-16T09:08:30.220623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Executar AutoML por tempo (ex: 600 segundos = 10 minutos)\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=600,            # ou use max_models=10 para limitar por nº de modelos\n",
    "    seed=42,\n",
    "    nfolds=5,\n",
    "    keep_cross_validation_predictions=True\n",
    ")\n",
    "\n",
    "# Treinar\n",
    "aml.train(x=features, y=target, training_frame=train)\n",
    "\n",
    "# Ver leaderboard\n",
    "lb = aml.leaderboard\n",
    "print(lb)\n",
    "\n",
    "# Ver melhor modelo\n",
    "best_model = aml.leader\n",
    "print(best_model.model_id)"
   ],
   "id": "ab8ec8de2e50aed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |█\n",
      "10:08:36.420: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n",
      "model_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
      "StackedEnsemble_AllModels_3_AutoML_1_20250416_100836     0.995459  0.081977   0.994599               0.0373714  0.15895   0.0252652\n",
      "StackedEnsemble_AllModels_2_AutoML_1_20250416_100836     0.995449  0.0820051  0.994587               0.0373152  0.159035  0.0252921\n",
      "StackedEnsemble_AllModels_1_AutoML_1_20250416_100836     0.995447  0.0820234  0.994584               0.0375719  0.159063  0.025301\n",
      "StackedEnsemble_BestOfFamily_4_AutoML_1_20250416_100836  0.995352  0.0829329  0.994481               0.0380266  0.159859  0.025555\n",
      "StackedEnsemble_BestOfFamily_2_AutoML_1_20250416_100836  0.995349  0.082892   0.994481               0.038037   0.159831  0.0255461\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_1_20250416_100836  0.995348  0.0828672  0.994465               0.0379116  0.160119  0.0256382\n",
      "StackedEnsemble_BestOfFamily_3_AutoML_1_20250416_100836  0.995348  0.0829327  0.994476               0.038071   0.159864  0.0255565\n",
      "StackedEnsemble_BestOfFamily_5_AutoML_1_20250416_100836  0.995348  0.0829319  0.994476               0.0381317  0.159875  0.0255599\n",
      "GBM_1_AutoML_1_20250416_100836                           0.995347  0.0827217  0.994465               0.0378959  0.160125  0.0256401\n",
      "GBM_4_AutoML_1_20250416_100836                           0.995201  0.0844933  0.994309               0.038248   0.160936  0.0259003\n",
      "[38 rows x 7 columns]\n",
      "\n",
      "StackedEnsemble_AllModels_3_AutoML_1_20250416_100836\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1. O mlhr modelo encontrado pelo AutoML é do mm tp do mlhr modelo encontrado nos exs anteriores? Se s, quais foram as diferenças observadas a nível de config?\n",
    "O mlhr modelo encontrado pelo AutoML foi tbm um Stacked Ensemble, cm no modelo treinado manualmente.\n",
    "No entanto, o AutoML mlhrou ligeiramente a performance geral, combinando um conj + alargado e variado de modelos base e testando diferentes configs automaticamente.\n",
    "A diferença principal está no facto de o ensemble do AutoML usar + modelos base e mlhres combinações, enqt o ensemble manual só utilizou DRF e GBM."
   ],
   "id": "b7aeb27d12c34aab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2. Cm se comparam os modelos, em termos de performance?\n",
    "Em termos de performance, o ensemble manual (Exercício 4) superou ligeiramente o mlhr modelo do AutoML, c uma AUC de 0.9993 contra 0.9955, e LogLoss significativamente + baixo (0.0457 vs 0.0819).\n",
    "\n",
    "Isto mostra q, apesar do AutoML ser extremamente eficaz pra encontrar bons modelos automaticamente, o ensemble construído manualmente c DRF e GBM, treinado c afinação cuidadosa, conseguiu mlhr desempenho final neste problema específico."
   ],
   "id": "a51483b8c8fc7ff2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
